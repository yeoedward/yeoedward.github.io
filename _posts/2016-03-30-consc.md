---
layout: post
title:  "Consciousness"
date:   2016-04-20
---

The part of Artificial intelligence I find most interesting is not so much the solving of 
problems intelligently, but rather computers having "a mind".

A natural first question in this line of inquiry, is whether or not it is
even possible for computers to think like humans. After all, computers
are pre-programmed and just mindlessly follow instructions.
But from what I have been taught about biology and physics, this is actually
the case for humans too. We are biologically-based, so our thoughts are
just neurons firing in a certain way. These neurons are governed by the laws
of physics. There is nothing to suggest that the human brain is more special (physically)
than an ant brain, or even weather patterns. In this sense, we too are mindlessly
obeying the laws of physics in our thoughts and actions.

So what, then, should the definition of consciousness
be? Something about the human brain makes it more interesting than the brain of an ant.
Sure, it is physically different, but the exciting part is the instructions that
both are "mindlessly" following. It was only lately, after taking a class on
[computability][flac], that
I have been exposed to the language and framework to think about this more precisely.
After all, computability can be thought of as the study of mindlessly following instructions.

The experience of free will seems like a paradox if we accept that we do not have it.
I believe this is resolved by [diagonalization][diag], in particular, [Rice's theorem][rice],
which I (very) loosely paraphrase as stating that it is impossible for a process capable
of self-reference to know how it is going to behave, because if it does know, it can decide
to behave differently. This trivial-sounding idea reminds me of a game that kids play, which 
is surprising because a lot of the computability proofs use similar arguments.
But anyway, I believe it is this that gives us the illusion of free will.
I am by no means the first one to have thought along
[these lines][turing_free_will]!

I have been searching for more formal models of consciousness, and have found
a few of Marvin Minsky's writings illuminating. He likens consciousness to a big [suitcase][suitcase] of
vague and ill-defined ideas, and thinks that it is more important to understand the "resourcefulness" of human
thought than to delve into subjective experiences as philosophers do. He also has a [theory of frames][frames] which might be a useful framework (pardon the pun) to think about consciousness. Here he seems to argue for the importance of searching for different representations for different problems. Consciousness seems to fit nicely here. Manuel Blum also has interesting ideas.

# To read/think:

The Society of Mind.

The Emotion Machine.

Automating Turing reductions? Changing between problem representations, like in Minsky's frames.

Blum's [definitions][blum] and [CONSCS][conscs].

Chaitin and [algorithmic information theory][chaitin].


[flac]: http://www.cs.cmu.edu/~flac/
[diag]: https://en.wikipedia.org/wiki/Diagonal_lemma
[rice]: https://en.wikipedia.org/wiki/Rice%27s_theorem
[turing_free_will]: http://arxiv.org/abs/1310.3225
[suitcase]: https://www.edge.org/conversation/marvin_minsky-consciousness-is-a-big-suitcase
[frames]: http://web.media.mit.edu/~minsky/papers/Frames/frames.html
[blum]: https://www.cs.cmu.edu/~mblum/research/pdf/cons.html
[conscs]: https://www.cs.cmu.edu/~mblum/search/consc_d.pdf
[chaitin]: https://en.wikipedia.org/wiki/Algorithmic_information_theory
